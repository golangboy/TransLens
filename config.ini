[DEFAULT]
provider = local_llama
system_prompt = 你是一个专业的中英翻译引擎，你的任务是只返回给定词语在上下文中的英文翻译，不要说任何无关的话，不要做任何解释。
# 引用 .env 文件中的 DEFAULT_PROXY 变量
# 如果 .env 中没有定义，则为空
proxy = ${DEFAULT_PROXY}

# ==========================================================
# ============ 在下面定义你的 API 提供者 ============
# ==========================================================

[local_llama]
api_url = http://localhost:8080/v1/chat/completions
model = local-model
use_system_role = true
api_key = no-key-required

# --- OpenRouter 配置示例 1 ---
[openrouter_gpt4o]
api_url = https://openrouter.ai/api/v1/chat/completions
# 引用 .env 文件中的 OPENROUTER_API_KEY 变量
api_key = ${OPENROUTER_API_KEY}
model = openai/gpt-4o
use_system_role = true
header_HTTP-Referer = http://localhost
header_X-Title = TransLens

# --- OpenRouter 配置示例 2 (使用不同模型) ---
[sonoma]
api_url = https://openrouter.ai/api/v1/chat/completions
# 同样引用 OpenRouter 密钥
api_key = ${OPENROUTER_API_KEY}
model = openrouter/sonoma-dusk-alpha
use_system_role = true
header_HTTP-Referer = http://localhost
header_X-Title = TransLens

# --- 不支持 System Role 的模型配置示例 ---
[custom_model_no_system]
api_url = http://some-other-api/v1/chat
api_key = ${YOUR_CUSTOM_API_KEY} # 也可以为其他服务定义变量
model = custom-model-v1
use_system_role = false